{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Ravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sent=SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['tweet_id', 'airline_sentiment_confidence', 'negativereason',\n",
    "       'negativereason_confidence', 'airline', 'airline_sentiment_gold',\n",
    "       'name', 'negativereason_gold', 'retweet_count', 'tweet_coord',\n",
    "       'tweet_created', 'tweet_location', 'user_timezone'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               data\n",
       "0   neutral                @VirginAmerica What @dhepburn said.\n",
       "1  positive  @VirginAmerica plus you've added commercials t...\n",
       "2   neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3  negative  @VirginAmerica it's really aggressive to blast...\n",
       "4  negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename({\"airline_sentiment\":\"Target\",\"text\":\"data\"},axis='columns',inplace=True)\n",
    "df[[\"Target\",\"data\"]].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This analysis mostly would be covered sentimentanalysis.Hence EDA is skipped here. Let's dive into new stuffs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  @VirginAmerica What @dhepburn said.\n",
       "1    @VirginAmerica plus you've added commercials t...\n",
       "2    @VirginAmerica I didn't today... Must mean I n...\n",
       "3    @VirginAmerica it's really aggressive to blast...\n",
       "4    @VirginAmerica and it's a really big bad thing...\n",
       "Name: url_removed, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "df[\"url_removed\"]=df.data.apply(lambda x:remove_urls(x))\n",
    "df[\"url_removed\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  @VirginAmerica What @dhepburn said.\n",
       "1    @VirginAmerica plus you've added commercials t...\n",
       "2    @VirginAmerica I didn't today... Must mean I n...\n",
       "3    @VirginAmerica it's really aggressive to blast...\n",
       "4    @VirginAmerica and it's a really big bad thing...\n",
       "Name: emoji, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "df[\"emoji\"]=df.url_removed.apply(lambda x:emoji(x))\n",
    "df[\"emoji\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  @VirginAmerica What @dhepburn said.\n",
       "1    @VirginAmerica plus you've added commercials t...\n",
       "2    @VirginAmerica I didn't today... Must mean I n...\n",
       "3    @VirginAmerica it's really aggressive to blast...\n",
       "4    @VirginAmerica and it's a really big bad thing...\n",
       "Name: numeric, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numeric(text):\n",
    "    return \"\".join([x for x in text if not x.isdigit()])\n",
    "df[\"numeric\"]=df.emoji.apply(lambda x:numeric(x))\n",
    "df[\"numeric\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [@, virginamerica, what, @, dhepburn, said, .]\n",
       "1    [@, virginamerica, plus, you, 've, added, comm...\n",
       "2    [@, virginamerica, i, did, n't, today, ..., mu...\n",
       "3    [@, virginamerica, it, 's, really, aggressive,...\n",
       "4    [@, virginamerica, and, it, 's, a, really, big...\n",
       "Name: token, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def cleaning(x):\n",
    "    y=x.lower()\n",
    "    return word_tokenize(y)\n",
    "df[\"token\"]=df.numeric.apply(lambda x:cleaning(x))\n",
    "df[\"token\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     virginamerica what dhepburn said\n",
       "1    virginamerica plus you 've added commercials t...\n",
       "2    virginamerica i did n't today ... must mean i ...\n",
       "3    virginamerica it 's really aggressive to blast...\n",
       "4    virginamerica and it 's a really big bad thing...\n",
       "Name: punctuation, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "def pun_removal(text):\n",
    "    no_pun=\" \".join([c for c in text if c not in string.punctuation])\n",
    "    return no_pun\n",
    "df[\"punctuation\"]=df.token.apply(lambda x:pun_removal(x))\n",
    "df[\"punctuation\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [virginamerica, dhepburn, said]\n",
       "1    [virginamerica, plus, added, commercials, expe...\n",
       "2    [virginamerica, today, must, mean, need, take,...\n",
       "3    [virginamerica, really, aggressive, blast, obn...\n",
       "4             [virginamerica, really, big, bad, thing]\n",
       "Name: stopword, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=set(stopwords.words(\"english\"))\n",
    "stop.update((\"n't\",\"'s\",\"ca\",\"since\",\"ravi\",\"cs\",\"'ve\",\"'ll\",\"'m\",\"still\",\"us\",\"...\"))\n",
    "def stopword(text):\n",
    "    removed=[]\n",
    "    for x in text.split():\n",
    "        if x not in stop:\n",
    "            removed.append(x)\n",
    "    return removed\n",
    "df[\"stopword\"]=df.punctuation.apply(lambda x:stopword(x))\n",
    "df[\"stopword\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           virginamerica dhepburn say\n",
       "1    virginamerica plus add commercials experience ...\n",
       "2    virginamerica today must mean need take anothe...\n",
       "3    virginamerica really aggressive blast obnoxiou...\n",
       "4                   virginamerica really big bad thing\n",
       "Name: lema, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "def lema(text):\n",
    "    w=WordNetLemmatizer()\n",
    "    str=\" \".join([w.lemmatize(x,wordnet.VERB) for x in text])\n",
    "    return str    \n",
    "df[\"lema\"]=df.stopword.apply(lambda x:lema(x))\n",
    "df.lema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pure\"]=df.lema.str.replace(\"“\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           virginamerica dhepburn say\n",
       "1    virginamerica plus add commercials experience ...\n",
       "2    virginamerica today must mean need take anothe...\n",
       "3    virginamerica really aggressive blast obnoxiou...\n",
       "4                   virginamerica really big bad thing\n",
       "Name: pure, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pure\"].replace({\"mins\":\"minutes\",\"hrs\":\"hours\",\"ppl\":\"people\"},regex=True,inplace=True)\n",
    "df[\"pure\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sent=SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "1    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "2    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "3    {'neg': 0.287, 'neu': 0.557, 'pos': 0.156, 'co...\n",
       "4    {'neg': 0.486, 'neu': 0.514, 'pos': 0.0, 'comp...\n",
       "Name: score, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(x):\n",
    "    return sent.polarity_scores(x)\n",
    "df[\"score\"]=df.pure.apply(lambda x:score(x))\n",
    "df[\"score\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0000\n",
       "1    0.0000\n",
       "2    0.0000\n",
       "3   -0.3306\n",
       "4   -0.5829\n",
       "Name: compound, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"compound\"]=df.score.apply(lambda x:x[\"compound\"])\n",
    "df[\"compound\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     neutral\n",
       "1     neutral\n",
       "2     neutral\n",
       "3    negative\n",
       "4    negative\n",
       "Name: result, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"result\"]=df[\"compound\"].apply(lambda x:\"positive\" if x>0 else (\"neutral\" if x==0 else \"negative\"))\n",
    "df[\"result\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target    result\n",
       "0   neutral   neutral\n",
       "1  positive   neutral\n",
       "2   neutral   neutral\n",
       "3  negative  negative\n",
       "4  negative  negative"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Target\",\"result\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5088114754098361\n",
      "[[4095 1937 3146]\n",
      " [ 413 1288 1398]\n",
      " [  89  208 2066]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.45      0.59      9178\n",
      "     neutral       0.38      0.42      0.39      3099\n",
      "    positive       0.31      0.87      0.46      2363\n",
      "\n",
      "    accuracy                           0.51     14640\n",
      "   macro avg       0.53      0.58      0.48     14640\n",
      "weighted avg       0.69      0.51      0.53     14640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(df.Target,df.result))\n",
    "print(confusion_matrix(df.Target,df.result))\n",
    "print(classification_report(df.Target,df.result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis results around 50% of accuracy which is quite less when  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
